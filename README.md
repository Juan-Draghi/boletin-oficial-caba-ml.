# Detector de Normativa Legal para Arquitectos (CPAU)

> **Automatizaci√≥n del relevamiento normativo mediante Machine Learning: Reduciendo la carga manual y minimizando el riesgo legal.**

Este proyecto implementa un pipeline de NLP supervisado para detectar autom√°ticamente normativa relevante para el ejercicio de la arquitectura y el urbanismo en el **Bolet√≠n Oficial de la Ciudad de Buenos Aires (BOGCBA)**.

Desarrollado como trabajo final para la Diplomatura en IA Aplicada (FCE‚ÄìUBA, 2025) y actualmente en producci√≥n para uso interno.

---

## üéØ El Problema de Negocio
Los bibliotecarios y referencistas del Consejo Profesional (CPAU) deben revisar diariamente cientos de p√°ginas de documentos legales para encontrar normas cr√≠ticas (c√≥digos de edificaci√≥n, habilitaciones, etc.).
* **El Costo:** Horas de lectura manual propensas a la fatiga.
* **El Riesgo:** Pasar por alto una modificaci√≥n normativa ("Falso Negativo") puede tener consecuencias legales graves para los matriculados.

## üí° La Soluci√≥n
Un clasificador binario que procesa los PDFs del Bolet√≠n Oficial, extrae fragmentos candidatos mediante heur√≠sticas y utiliza un modelo de Machine Learning para determinar su pertinencia con un **Recall (Sensibilidad) superior al 85%**.

---

## üöÄ Hallazgos T√©cnicos Clave: SVM vs. LLMs
Uno de los puntos m√°s interesantes de este proyecto fue la comparativa de costo-efectividad entre m√©todos cl√°sicos y Deep Learning.

| Enfoque | Modelo | Resultado | Conclusi√≥n |
| :--- | :--- | :--- | :--- |
| **ML Cl√°sico** | **TF-IDF + SVM** | üèÜ **Ganador** | Mejor manejo de pocos datos, m√°s r√°pido, F1-Score superior (0.75). |
| **LLM Fine-Tuning** | **RoBERTalex** | üìâ Inferior | Sufri√≥ de *overfitting* por el tama√±o del dataset y desajuste de dominio (Espa√±a vs. Argentina). |

**Decisi√≥n de Arquitectura:** Se implement√≥ **SVM** en producci√≥n. Esto demuestra que, para tareas de clasificaci√≥n de texto con dominios muy espec√≠ficos y datasets limitados (<3000 ejemplos), un modelo cl√°sico bien calibrado suele superar a los Transformers, siendo infinitamente m√°s barato de mantener.

---

## üìä Metodolog√≠a y M√©tricas

### 1. Enfoque "Recall-First"
En el √°mbito legal, un Falso Positivo (leer una norma irrelevante) es una molestia menor, pero un **Falso Negativo (perderse una ley) es inaceptable**.
* Se optimiz√≥ el modelo priorizando la m√©trica **F2-Score** y el **Recall**.
* El umbral de decisi√≥n no es el est√°ndar (0.5), sino uno calibrado espec√≠ficamente para capturar la mayor cantidad de positivos posibles.

### 2. Construcci√≥n del Dataset (Human-in-the-loop)
* **Fuente:** PDFs del BOGCBA (2018‚Äì2025).
* **Curaci√≥n:** Etiquetado manual asistido por una interfaz en **Gradio**.
* **Split Temporal:** Train (2018-2024) / Test (2025). Se valida con "el futuro" para simular el escenario real de producci√≥n.

---

## üõ†Ô∏è Stack Tecnol√≥gico y Pipeline

El sistema funciona con un flujo de 3 etapas modularizadas:

1.  **Ingesta y Filtrado (Reglas):**
    * Extracci√≥n de texto de PDF.
    * Triangulaci√≥n de candidatos usando Regex: `VERBOS_ACCION` + (`KEYWORDS` o `PATRONES_NORMATIVOS`).
2.  **Clasificaci√≥n (ML):**
    * Vectorizaci√≥n TF-IDF (1-2 n-grams).
    * Inferencia con Support Vector Machine (SVM).
3.  **Feedback Loop (Mejora Continua):**
    * Interfaz visual (Gradio) para que el experto humano valide las predicciones diarias.
    * Los errores del modelo se reinyectan en el dataset de entrenamiento (`08_BO_SVM_retrain.ipynb`).

---

## üìÇ Estructura del Repositorio

```text
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ 01-03_Dataset_Builder/   # Extracci√≥n, limpieza y etiquetado (Gradio)
‚îÇ   ‚îú‚îÄ‚îÄ 04_Baseline_ML/          # Comparativa: Regresi√≥n Log√≠stica, Naive Bayes, RF, SVM
‚îÇ   ‚îú‚îÄ‚îÄ 05_FineTuning_LLM/       # Experimentos con RoBERTalex (Hugging Face)
‚îÇ   ‚îî‚îÄ‚îÄ 06-08_Production/        # Pipeline diario: Inferencia -> Feedback -> Reentrenamiento
‚îú‚îÄ‚îÄ data/                        # Datasets (train/val/test) anonimizados
‚îú‚îÄ‚îÄ models/                      # Serializados (.pkl) del modelo ganador
‚îî‚îÄ‚îÄ docs/                        # Informe t√©cnico detallado
```

## üîÑ Evoluci√≥n del proyecto

Este trabajo es la cuarta iteraci√≥n de una serie de prototipos para automatizar el relevamiento normativo en el Bolet√≠n Oficial de CABA:

1. **v1 ‚Äì B√∫squeda por palabras clave**  
   Script en Python que recorre PDFs y exporta coincidencias a Excel.

2. **v2 ‚Äì Palabras clave + verbos de acci√≥n normativa**  
   Reducci√≥n de falsos positivos incorporando verbos como "aprueba", "deroga", etc.

3. **v3 ‚Äì LLM v√≠a API**  
   Uso de un modelo de lenguaje para evaluar la relevancia de los fragmentos candidatos.

4. **v4 ‚Äì Clasificaci√≥n supervisada (repo actual)**  
   Construcci√≥n de un dataset etiquetado, entrenamiento de modelos cl√°sicos de ML, 
   exploraci√≥n de fine-tuning y despliegue de un pipeline SVM + TF-IDF.


## ‚úíÔ∏è Autor

Juan Draghi ‚Äì Bibliotecario, Consejo Profesional de Arquitectura y Urbanismo (CPAU).
Este proyecto fue desarrollado como trabajo final de la Diplomatura en IA Aplicada a Entornos Digitales de Gesti√≥n (FCE‚ÄìUBA, 2025)

## Uso de herramientas de IA

Parte del dise√±o metodol√≥gico, del c√≥digo en Python y de la documentaci√≥n de este proyecto fue asistida mediante el uso de modelos de lenguaje (ChatGPT, OpenAI), utilizados como apoyo durante la cursada de la Diplomatura en Inteligencia Artificial.

Las decisiones de dise√±o, la definici√≥n del problema, la curadur√≠a del dataset y la validaci√≥n de resultados fueron realizadas por el autor.

