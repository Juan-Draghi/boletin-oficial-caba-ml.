# Detector de Normativa Legal para Arquitectos

> Desarrollado como trabajo final de la **Diplomatura en Inteligencia Artificial Aplicada a Entornos Digitales de Gesti√≥n (FCE‚ÄìUBA, 2025)**.

Este proyecto implementa un pipeline de NLP supervisado para detectar autom√°ticamente normativa relevante para el ejercicio profesional de la arquitectura y el urbanismo en el **Bolet√≠n Oficial de la Ciudad de Buenos Aires**.

---

## üéØ Definici√≥n del Problema
Los bibliotecarios del Consejo Profesional de Arquitectura y Urbanismo (CPAU) deben revisar diariamente el Bolet√≠n Oficial de la Ciudad de Buenos Aires para detectar normas referidas a construcci√≥n, planificaci√≥n urbana, habilitaciones comerciales, impacto ambiental, seguridad e higiene, planes de evacuaci√≥n, uso del espacio p√∫blico, etc.

Esta revisi√≥n se realiza de forma manual y, dado que cada ejemplar tiene cientos de p√°ginas, la posibilidad de pasar por alto una norma relevante es elevada.


## üí° La Soluci√≥n
Un clasificador binario que procesa los PDFs del Bolet√≠n Oficial, extrae fragmentos candidatos mediante heur√≠sticas y utiliza un modelo de Machine Learning para determinar su pertinencia con un **Recall (Sensibilidad) superior al 85%**.

---

## üöÄ Hallazgos T√©cnicos Clave: SVM vs. LLMs
Uno de los puntos m√°s interesantes de este proyecto fue la comparativa de costo-efectividad entre m√©todos cl√°sicos y Deep Learning.

| Enfoque | Modelo | Resultado | Conclusi√≥n |
| :--- | :--- | :--- | :--- |
| **ML Cl√°sico** | **TF-IDF + SVM** | üèÜ **Ganador** | Mejor manejo de pocos datos, m√°s r√°pido, F1-Score superior (0.75). |
| **LLM Fine-Tuning** | **RoBERTalex** | üìâ Inferior | Sufri√≥ de *overfitting* por el tama√±o del dataset y desajuste de dominio (Espa√±a vs. Argentina). |

**Decisi√≥n de Arquitectura:** Se implement√≥ **SVM** en producci√≥n. Esto demuestra que, para tareas de clasificaci√≥n de texto con dominios muy espec√≠ficos y datasets limitados (<3000 ejemplos), un modelo cl√°sico bien calibrado suele superar a los Transformers, siendo infinitamente m√°s barato de mantener.

---

## üìä Metodolog√≠a y M√©tricas

### 1. Enfoque "Recall-First"
En el √°mbito legal, un Falso Positivo (leer una norma irrelevante) es una molestia menor, pero un **Falso Negativo (perderse una ley) es inaceptable**.
* Se optimiz√≥ el modelo priorizando el **Recall**.
* El umbral de decisi√≥n no es el est√°ndar (0.5), sino uno calibrado espec√≠ficamente para capturar la mayor cantidad de positivos posibles.

### 2. Construcci√≥n del Dataset
* **Fuente:** PDFs del BOGCBA (2018‚Äì2025).
* **Curaci√≥n:** Etiquetado manual asistido por una interfaz en **Gradio**.
* **Split Temporal:** Train (2018 ‚Äì 1er semestre de 2024) / Val (2¬∫ semestre de 2024) / Test (2025). Se valida con "el futuro" para simular el escenario real de producci√≥n.

---

## üõ†Ô∏è Stack Tecnol√≥gico y Pipeline

El sistema funciona con un flujo de 3 etapas modularizadas:

1.  **Ingesta y Filtrado (Reglas):**
    * Extracci√≥n de texto de PDF.
    * Triangulaci√≥n de candidatos usando Regex: `VERBOS_ACCION` + (`KEYWORDS` o `PATRONES_NORMATIVOS`).
2.  **Clasificaci√≥n (ML):**
    * Vectorizaci√≥n TF-IDF (1-2 n-grams).
    * Inferencia con Support Vector Machine (SVM).
3.  **Feedback Loop (Mejora Continua):**
    * Interfaz visual (Gradio) para que el experto humano valide las predicciones diarias.
    * Los nuevos registros se reinyectan en el dataset de entrenamiento (`08_BO_SVM_retrain.ipynb`).

---

## üìÇ Estructura del Repositorio

```text
boletin-oficial-caba-ml/
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ 01_Dataset_Builder_v1_.ipynb               # Extracci√≥n de datos
‚îÇ   ‚îú‚îÄ‚îÄ 02_Triage_v1_etiquetas.ipynb               # Limpieza de datos
‚îÇ   ‚îú‚îÄ‚îÄ 03_Editor_Gradio_BO_CSV.ipynb              # Etiquetado
‚îÇ   ‚îú‚îÄ‚îÄ 04_Baseline_BO_CABA_TFIDF_4modelos.ipynb   # Comparativa: Regresi√≥n Log√≠stica, Naive Bayes, Random Forest, SVM
‚îÇ   ‚îú‚îÄ‚îÄ 05_FineTuning_v1_ES_Legal.ipynb            # Experimento con RoBERTalex (Hugging Face)
‚îÇ   ‚îú‚îÄ‚îÄ 06_BO_SVM.ipynb                            # Pipeline diario: Inferencia
|   ‚îú‚îÄ‚îÄ 07_BO_SVM_feedback.ipynb                   # Pipeline diario: Feedback
‚îÇ   ‚îî‚îÄ‚îÄ 08_BO_SVM_retrain.ipynb                    # Pipeline diario: Reentrenamiento
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îî‚îÄ‚îÄ labels/
‚îÇ       ‚îú‚îÄ‚îÄ dataset_train_final.csv
‚îÇ       ‚îú‚îÄ‚îÄ dataset_val_final.csv
‚îÇ       ‚îî‚îÄ‚îÄ dataset_test_final.csv
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îî‚îÄ‚îÄ baseline
‚îÇ   ‚îî‚îÄ‚îÄ demo_svm
‚îÇ   ‚îî‚îÄ‚îÄ finetuning
‚îÇ   ‚îî‚îÄ‚îÄ svm_tfidf_v1
‚îú‚îÄ‚îÄ metrics/
‚îÇ   ‚îî‚îÄ‚îÄ baseline
‚îÇ   ‚îî‚îÄ‚îÄ finetuning
‚îÇ   ‚îî‚îÄ‚îÄ metricas_comparativa.xls
‚îî‚îÄ‚îÄ docs/
    ‚îî‚îÄ‚îÄ Draghi_Informe_TP_Final.pdf  # Informe t√©cnico detallado
```

## üîÑ Evoluci√≥n del proyecto

Este trabajo es la cuarta iteraci√≥n de una serie de prototipos para automatizar el relevamiento normativo en el Bolet√≠n Oficial de CABA:

1. **v1 ‚Äì B√∫squeda por palabras clave**  
   Script en Python que recorre PDFs y exporta coincidencias a Excel.

2. **v2 ‚Äì Palabras clave + verbos de acci√≥n normativa**  
   Reducci√≥n de falsos positivos incorporando verbos como "aprueba", "deroga", etc.

3. **v3 ‚Äì LLM v√≠a API**  
   Uso de un modelo de lenguaje para evaluar la relevancia de los fragmentos candidatos.

4. **v4 ‚Äì Clasificaci√≥n supervisada (repo actual)**  
   Construcci√≥n de un dataset etiquetado, entrenamiento de modelos cl√°sicos de ML, 
   exploraci√≥n de fine-tuning y despliegue de un pipeline SVM + TF-IDF.


## ‚úíÔ∏è Autor

Juan Draghi ‚Äì Bibliotecario, Consejo Profesional de Arquitectura y Urbanismo (CPAU).
Este proyecto fue desarrollado como trabajo final de la Diplomatura en IA Aplicada a Entornos Digitales de Gesti√≥n (FCE‚ÄìUBA, 2025)

## Uso de herramientas de IA

Parte del dise√±o metodol√≥gico, del c√≥digo en Python y de la documentaci√≥n de este proyecto fue asistida mediante el uso de modelos de lenguaje (ChatGPT, OpenAI), utilizados como apoyo durante la cursada de la Diplomatura en Inteligencia Artificial.

Las decisiones de dise√±o, la definici√≥n del problema, la curadur√≠a del dataset y la validaci√≥n de resultados fueron realizadas por el autor.

