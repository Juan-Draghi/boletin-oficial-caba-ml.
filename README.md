# Detector de Normativa Legal para Arquitectos

> Desarrollado como trabajo final de la **Diplomatura en Inteligencia Artificial Aplicada a Entornos Digitales de GestiÃ³n (FCEâ€“UBA, 2025)**.

Este proyecto implementa un pipeline de NLP supervisado para detectar automÃ¡ticamente normativa relevante para el ejercicio profesional de la arquitectura y el urbanismo en el **BoletÃ­n Oficial de la Ciudad de Buenos Aires**.

---

## ğŸ¯ DefiniciÃ³n del Problema
Los bibliotecarios del Consejo Profesional de Arquitectura y Urbanismo (CPAU) deben revisar diariamente el BoletÃ­n Oficial de la Ciudad de Buenos Aires para detectar normas referidas a construcciÃ³n, planificaciÃ³n urbana, habilitaciones comerciales, impacto ambiental, seguridad e higiene, planes de evacuaciÃ³n, uso del espacio pÃºblico, etc.

Esta revisiÃ³n se realiza de forma manual y, dado que cada ejemplar tiene cientos de pÃ¡ginas, la posibilidad de pasar por alto una norma relevante es elevada.


## ğŸ’¡ La SoluciÃ³n
Un clasificador binario que procesa los PDFs del BoletÃ­n Oficial, extrae fragmentos candidatos mediante heurÃ­sticas y utiliza un modelo de Machine Learning para determinar su pertinencia con un **Recall (Sensibilidad) superior al 85%**.

---

## ğŸš€ Hallazgos TÃ©cnicos Clave: SVM vs. Transformers
Uno de los puntos mÃ¡s interesantes de este proyecto fue la comparativa de costo-efectividad entre mÃ©todos clÃ¡sicos y Deep Learning.

| Enfoque | Modelo | Resultado | ConclusiÃ³n |
| :--- | :--- | :--- | :--- |
| **ML ClÃ¡sico** | **TF-IDF + SVM** | ğŸ† **Ganador** | Mejor manejo de pocos datos, mÃ¡s rÃ¡pido, F1-Score superior (0.75). |
| **Transformer** | **RoBERTalex** | ğŸ“‰ Inferior | No logrÃ³ especializarse por el tamaÃ±o del dataset y desajuste de dominio (EspaÃ±a vs. Argentina). |

**DecisiÃ³n de Arquitectura:** Se implementÃ³ **SVM** en producciÃ³n. Esto demuestra que, para tareas de clasificaciÃ³n de texto con dominios muy especÃ­ficos y datasets limitados (<3000 ejemplos), un modelo clÃ¡sico bien calibrado suele superar a los Transformers, siendo infinitamente mÃ¡s barato de mantener.

---

## ğŸ“Š MetodologÃ­a y MÃ©tricas

### 1. Enfoque "Recall-First"
En el Ã¡mbito legal, un Falso Positivo (leer una norma irrelevante) es una molestia menor, pero un **Falso Negativo (perderse una ley) es inaceptable**.
* Se optimizÃ³ el modelo priorizando el **Recall**.
* El umbral de decisiÃ³n no es el estÃ¡ndar (0.5), sino uno calibrado especÃ­ficamente para capturar la mayor cantidad de positivos posibles.

### 2. ConstrucciÃ³n del Dataset
* **Fuente:** PDFs del BOGCBA (2018â€“2025).
* **CuraciÃ³n:** Etiquetado manual asistido por una interfaz en **Gradio**.
* **Split Temporal:** Train (2018 â€“ 1er semestre de 2024) / Val (2Âº semestre de 2024) / Test (2025). Se valida con "el futuro" para simular el escenario real de producciÃ³n.

---

## ğŸ› ï¸ Stack TecnolÃ³gico y Pipeline

El sistema funciona con un flujo de 3 etapas modularizadas:

1.  **Ingesta y Filtrado (Reglas):**
    * ExtracciÃ³n de texto de PDF.
    * TriangulaciÃ³n de candidatos usando Regex: `VERBOS_ACCION` + (`KEYWORDS` o `PATRONES_NORMATIVOS`).
2.  **ClasificaciÃ³n (ML):**
    * VectorizaciÃ³n TF-IDF (1-2 n-grams).
    * Inferencia con Support Vector Machine (SVM).
3.  **Feedback Loop (Mejora Continua):**
    * Interfaz visual (Gradio) para que el experto humano valide las predicciones diarias.
    * Los nuevos registros se reinyectan en el dataset de entrenamiento (`08_BO_SVM_retrain.ipynb`).

---

## ğŸ“‚ Estructura del Repositorio

```text
boletin-oficial-caba-ml/
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_Dataset_Builder/          # ExtracciÃ³n, limpieza y etiquetado (Gradio)
â”‚   â”œâ”€â”€ 02_Baseline_ML/              # Comparativa: RegresiÃ³n LogÃ­stica, Naive Bayes, Random Forest, SVM
â”‚   â”œâ”€â”€ 03_FineTuning_LLM/           # Experimento con RoBERTalex (Hugging Face)
â”‚   â”œâ”€â”€ 04_Production/               # Pipeline diario: Inferencia -> Feedback -> Reentrenamiento
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ dataset_train.csv
â”‚   â”œâ”€â”€ dataset_val.csv
â”‚   â””â”€â”€ dataset_test.csv
â”œâ”€â”€ models/
â”‚   â””â”€â”€ demo_svm/
â”‚   â””â”€â”€ finetuning/
â”œâ”€â”€ metrics/
â”‚   â””â”€â”€ baseline
â”‚   â””â”€â”€ finetuning
â”‚   â””â”€â”€ metricas_comparativa.csv
â””â”€â”€ docs/
    â””â”€â”€ Draghi_Informe_TP_Final.pdf  # Informe tÃ©cnico detallado
```

## ğŸ”„ EvoluciÃ³n del proyecto

Este trabajo es la cuarta iteraciÃ³n de una serie de prototipos para automatizar el relevamiento normativo en el BoletÃ­n Oficial de CABA:

1. **v1 â€“ BÃºsqueda por palabras clave**  
   Script en Python que recorre PDFs y exporta coincidencias a Excel.

2. **v2 â€“ Palabras clave + verbos de acciÃ³n normativa**  
   ReducciÃ³n de falsos positivos incorporando verbos como "aprueba", "deroga", etc.

3. **v3 â€“ LLM vÃ­a API**  
   Uso de un modelo de lenguaje para evaluar la relevancia de los fragmentos candidatos.

4. **v4 â€“ ClasificaciÃ³n supervisada (repo actual)**  
   ConstrucciÃ³n de un dataset etiquetado, entrenamiento de modelos clÃ¡sicos de ML, 
   exploraciÃ³n de fine-tuning y despliegue de un pipeline SVM + TF-IDF.


## âœ’ï¸ Autor

Juan Draghi â€“ Bibliotecario, Consejo Profesional de Arquitectura y Urbanismo (CPAU).
Este proyecto fue desarrollado como trabajo final de la Diplomatura en IA Aplicada a Entornos Digitales de GestiÃ³n (FCEâ€“UBA, 2025)

## Uso de herramientas de IA

Parte del diseÃ±o metodolÃ³gico, del cÃ³digo en Python y de la documentaciÃ³n de este proyecto fue asistida mediante el uso de modelos de lenguaje (ChatGPT, OpenAI), utilizados como apoyo durante la cursada de la Diplomatura en Inteligencia Artificial.

Las decisiones de diseÃ±o, la definiciÃ³n del problema, la curadurÃ­a del dataset y la validaciÃ³n de resultados fueron realizadas por el autor.

