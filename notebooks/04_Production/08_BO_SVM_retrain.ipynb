{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPq/vJ8hlYiTtzOtSRN3bEn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Re entrenamiento del modelo SVM+TF-IDF con datos actualizados**\n","\n","CÃ³mo usar este notebook en la rutina de revisiÃ³n del BoletÃ­n Oficial:\n","\n","1. Inferencia diaria (BO_SVM.ipynb) â†’ _svm_preds.csv.\n","\n","2. RevisiÃ³n en la interfaz Gradio (BO_SVM_feedback.ipynb) â†’ actualiza train_feedback_master.csv.\n","\n","Una vez que se haya juntado una cantidad suficiente de nuevos registros etiquetados, se corre este notebook para realizar el reentrenamiento de SVM con TRAIN + FEEDBACK, usa VAL para recalcular umbrales y evalÃºa en TEST.\n","\n","Guarda un nuevo svm_tfidf_pipeline.joblib e imprime el nuevo thr_f2, el cual debe actualizarse en el notebook de inferencia (BO_SVM.ipynb, celda 4)"],"metadata":{"id":"E9PXQoe-MTh8"}},{"cell_type":"markdown","source":["## **Celda 1 â€“ Montar Drive, imports y rutas**"],"metadata":{"id":"3sLPofP6MmDd"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"kbTwvv41MH7s"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import os\n","import pandas as pd\n","import numpy as np\n","\n","BASE = \"/content/drive/MyDrive/IA/Proyectos/AnÃ¡lisis BoletÃ­n Oficial/boletin-ml\"\n","CSV_TRAIN = os.path.join(BASE, \"data\", \"labels\", \"dataset_train_final.csv\")\n","CSV_VAL   = os.path.join(BASE, \"data\", \"labels\", \"dataset_val_final.csv\")\n","CSV_TEST  = os.path.join(BASE, \"data\", \"labels\", \"dataset_test_final.csv\")\n","\n","# Feedback acumulado desde la interfaz Gradio\n","CSV_FEEDBACK = os.path.join(BASE, \"data\", \"labels\", \"train_feedback_master.csv\")\n","\n","# DÃ³nde guardamos el modelo SVM+TFIDF (mismo que usa la demo)\n","MODEL_DIR  = os.path.join(BASE, \"models\", \"demo_svm\")\n","os.makedirs(MODEL_DIR, exist_ok=True)\n","MODEL_PATH = os.path.join(MODEL_DIR, \"svm_tfidf_pipeline.joblib\")\n","\n","print(\"BASE:\", BASE)\n","print(\"TRAIN:\", CSV_TRAIN)\n","print(\"VAL:\", CSV_VAL)\n","print(\"TEST:\", CSV_TEST)\n","print(\"FEEDBACK:\", CSV_FEEDBACK)\n","print(\"MODEL_PATH:\", MODEL_PATH)"]},{"cell_type":"markdown","source":["## **Celda 2 â€“ Funciones para cargar y unificar datasets**"],"metadata":{"id":"UvOqxLHJcPbC"}},{"cell_type":"code","source":["def read_csv_semicolon(path):\n","    return pd.read_csv(\n","        path,\n","        sep=\";\",\n","        encoding=\"utf-8-sig\",\n","        dtype=str,\n","        keep_default_na=False\n","    )\n","\n","def coerce_label(series):\n","    \"\"\"Asegura que label sea 0/1 (int). Lanza error si hay valores raros.\"\"\"\n","    s = series.astype(str).str.strip()\n","    s = s.replace({\"True\": \"1\", \"False\": \"0\"})\n","    if not set(s.unique()).issubset({\"0\", \"1\"}):\n","        raise ValueError(f\"Valores no binarios en 'label': {s.unique()}\")\n","    return s.astype(int)\n","\n","def load_split(path, name=\"\"):\n","    df = read_csv_semicolon(path)\n","    if \"contexto\" not in df.columns:\n","        raise ValueError(f\"{name}: falta columna 'contexto'\")\n","    if \"label\" not in df.columns:\n","        raise ValueError(f\"{name}: falta columna 'label' (0/1)\")\n","\n","    df[\"contexto\"] = df[\"contexto\"].astype(str).str.strip()\n","    df[\"label\"] = coerce_label(df[\"label\"])\n","\n","    # Eliminar filas sin texto\n","    before = len(df)\n","    df = df[df[\"contexto\"].str.strip().ne(\"\")]\n","    after = len(df)\n","\n","    print(f\"{name}: {before} filas, {after} con texto no vacÃ­o.\")\n","    print(f\"{name}: distribuciÃ³n de clases:\\n{df['label'].value_counts().sort_index()}\\n\")\n","    return df\n","\n","train_df = load_split(CSV_TRAIN, \"TRAIN\")\n","val_df   = load_split(CSV_VAL,   \"VAL\")\n","test_df  = load_split(CSV_TEST,  \"TEST\")\n","\n","if os.path.exists(CSV_FEEDBACK):\n","    fb_df = load_split(CSV_FEEDBACK, \"FEEDBACK\")\n","    print(\"FEEDBACK cargado.\")\n","else:\n","    fb_df = pd.DataFrame(columns=train_df.columns)\n","    print(\"No se encontrÃ³ feedback, se usarÃ¡ solo TRAIN base.\")\n","\n","# ðŸ‘‰ Para reentrenar en producciÃ³n:\n","# entrenamiento = TRAIN base + FEEDBACK\n","train_full = pd.concat([train_df, fb_df], ignore_index=True)\n","\n","print(\"=== RESUMEN ===\")\n","print(\"train_full:\", len(train_full))\n","print(\"val:\", len(val_df))\n","print(\"test:\", len(test_df))\n","print(\"DistribuciÃ³n train_full:\\n\", train_full[\"label\"].value_counts().sort_index())"],"metadata":{"id":"GBqnXCqHcfxR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Celda 3 â€“ Definir SVM+TF-IDF y GridSearchCV**"],"metadata":{"id":"O9Hk7fhHclm9"}},{"cell_type":"code","source":["!pip install scikit-learn > /dev/null\n","\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.svm import LinearSVC\n","from sklearn.pipeline import Pipeline\n","from sklearn.model_selection import StratifiedKFold, GridSearchCV\n","\n","from sklearn.metrics import (\n","    average_precision_score,\n","    roc_auc_score,\n",")\n","\n","TEXT_COL = \"contexto\"\n","\n","X_train = train_full[TEXT_COL].values\n","y_train = train_full[\"label\"].values\n","\n","# Pipeline TF-IDF + SVM (ajusta si querÃ©s cambiar n-gramas, min_df, etc.)\n","svm_pipe = Pipeline([\n","    (\"tfidf\", TfidfVectorizer(\n","        lowercase=True,\n","        strip_accents=None,\n","        ngram_range=(1, 2),\n","        min_df=2,\n","        max_df=0.9,\n","    )),\n","    (\"clf\", LinearSVC())\n","])\n","\n","param_grid = {\n","    \"clf__C\": [0.2, 1.0, 5.0]  # mismo rango que en el baseline\n","}\n","\n","cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n","\n","scoring = {\n","    \"ap\": \"average_precision\",  # AUC-PR\n","    \"roc\": \"roc_auc\",\n","}\n","\n","grid = GridSearchCV(\n","    svm_pipe,\n","    param_grid=param_grid,\n","    scoring=scoring,\n","    refit=\"ap\",   # se queda con el mejor modelo segÃºn AUC-PR\n","    cv=cv,\n","    n_jobs=-1,\n","    verbose=2\n",")\n","\n","print(\"Entrenando GridSearchCV sobre train_full...\")\n","grid.fit(X_train, y_train)\n","\n","print(\"Mejores hiperparÃ¡metros:\", grid.best_params_)\n","print(\"Mejor AUC-PR en CV:\", grid.best_score_)"],"metadata":{"id":"CMEf5pz1cpkx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Celda 4 â€“ Buscar umbral t_F2 usando el set de validaciÃ³n**"],"metadata":{"id":"FrOpEPPrcylU"}},{"cell_type":"code","source":["from sklearn.metrics import precision_recall_fscore_support\n","\n","best_svm = grid.best_estimator_\n","\n","X_val = val_df[TEXT_COL].values\n","y_val = val_df[\"label\"].values\n","\n","# LinearSVC no tiene predict_proba, usamos decision_function\n","scores_val = best_svm.decision_function(X_val)\n","\n","def eval_at_threshold(y_true, scores, thr, beta=2.0):\n","    y_pred = (scores >= thr).astype(int)\n","    tp = int(((y_true == 1) & (y_pred == 1)).sum())\n","    fn = int(((y_true == 1) & (y_pred == 0)).sum())\n","    fp = int(((y_true == 0) & (y_pred == 1)).sum())\n","    tn = int(((y_true == 0) & (y_pred == 0)).sum())\n","    prec = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n","    rec  = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n","    if prec + rec > 0:\n","        f_beta = (1 + beta**2) * prec * rec / (beta**2 * prec + rec)\n","    else:\n","        f_beta = 0.0\n","    return dict(\n","        thr=thr,\n","        precision=prec,\n","        recall=rec,\n","        f_beta=f_beta,\n","        tp=tp, fn=fn, fp=fp, tn=tn\n","    )\n","\n","# Para no evaluar en TODOS los scores, tomamos una grilla de cuantiles\n","unique_scores = np.unique(scores_val)\n","qs = np.linspace(0.05, 0.95, 50)\n","thr_candidates = np.quantile(unique_scores, qs)\n","\n","rows = [eval_at_threshold(y_val, scores_val, thr) for thr in thr_candidates]\n","thr_df = pd.DataFrame(rows)\n","\n","best_f2_row = thr_df.sort_values(\"f_beta\", ascending=False).iloc[0]\n","thr_f2 = float(best_f2_row[\"thr\"])\n","\n","print(\"=== Mejor umbral t_F2 en VALIDACIÃ“N ===\")\n","print(best_f2_row)\n","\n","auc_roc_val = roc_auc_score(y_val, scores_val)\n","auc_pr_val  = average_precision_score(y_val, scores_val)\n","print(f\"AUC-ROC (val): {auc_roc_val:.3f}\")\n","print(f\"AUC-PR  (val): {auc_pr_val:.3f}\")"],"metadata":{"id":"MBWFNYfuc2i-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Celda 5 â€“ Evaluar en TEST con t_F2**"],"metadata":{"id":"vTDrl1jbdA75"}},{"cell_type":"code","source":["from sklearn.metrics import classification_report, confusion_matrix\n","\n","X_test = test_df[TEXT_COL].values\n","y_test = test_df[\"label\"].values\n","\n","scores_test = best_svm.decision_function(X_test)\n","\n","def eval_on_test(y_true, scores, thr):\n","    y_pred = (scores >= thr).astype(int)\n","    tp = int(((y_true == 1) & (y_pred == 1)).sum())\n","    fn = int(((y_true == 1) & (y_pred == 0)).sum())\n","    fp = int(((y_true == 0) & (y_pred == 1)).sum())\n","    tn = int(((y_true == 0) & (y_pred == 0)).sum())\n","\n","    prec = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n","    rec  = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n","    f1   = (2 * prec * rec / (prec + rec)) if (prec + rec) > 0 else 0.0\n","\n","    beta = 2.0\n","    if prec + rec > 0:\n","        f2 = (1 + beta**2) * prec * rec / (beta**2 * prec + rec)\n","    else:\n","        f2 = 0.0\n","\n","    auc_roc = roc_auc_score(y_true, scores)\n","    auc_pr  = average_precision_score(y_true, scores)\n","\n","    return {\n","        \"precision\": prec,\n","        \"recall\": rec,\n","        \"f1\": f1,\n","        \"f2\": f2,\n","        \"tp\": tp, \"fn\": fn, \"fp\": fp, \"tn\": tn,\n","        \"auc_roc\": auc_roc,\n","        \"auc_pr\": auc_pr,\n","    }\n","\n","test_metrics = eval_on_test(y_test, scores_test, thr_f2)\n","\n","print(\"=== MÃ©tricas en TEST (usando t_F2) ===\")\n","for k, v in test_metrics.items():\n","    if isinstance(v, float):\n","        print(f\"{k}: {v:.3f}\")\n","    else:\n","        print(f\"{k}: {v}\")\n","\n","print(\"\\nMatriz de confusiÃ³n (TEST):\")\n","print(confusion_matrix(y_test, (scores_test >= thr_f2).astype(int)))\n","\n","print(\"\\nReporte de clasificaciÃ³n (TEST):\")\n","print(classification_report(y_test, (scores_test >= thr_f2).astype(int)))"],"metadata":{"id":"4sVubu2NdEP6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Celda 6 â€“ Guardar el modelo y (opcional) los umbrales**"],"metadata":{"id":"RuUhy_lmdLCq"}},{"cell_type":"code","source":["from joblib import dump\n","import json\n","\n","dump(best_svm, MODEL_PATH)\n","print(\"Modelo guardado en:\", MODEL_PATH)\n","print(\"CopiÃ¡ este valor a THRESHOLD_SVM en el notebook de inferencia:\")\n","print(\"thr_f2 =\", thr_f2)\n","\n","# Opcional: guardar umbrales en JSON\n","thr_info = {\n","    \"thr_f2\": float(thr_f2),\n","    \"thr_rtarget\": float(thr_rtarget) if \"thr_rtarget\" in locals() else None,\n","}\n","THR_JSON = os.path.join(MODEL_DIR, \"svm_thresholds.json\")\n","with open(THR_JSON, \"w\", encoding=\"utf-8\") as f:\n","    json.dump(thr_info, f, indent=2, ensure_ascii=False)\n","\n","print(\"Umbrales guardados en:\", THR_JSON)"],"metadata":{"id":"YOWVoMfUdO-D"},"execution_count":null,"outputs":[]}]}
